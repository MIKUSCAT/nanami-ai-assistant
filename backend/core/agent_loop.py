"""
Agent æ ¸å¿ƒå¾ªç¯ï¼ˆå«è®°å¿†ã€å‹ç¼©ã€å·¥å…·è°ƒç”¨ã€é•¿æœŸè®°å¿†æç‚¼ï¼‰

ç‰¹æ€§ï¼š
- å‚ï¿½?Claude Code çš„æ€è·¯ï¼šå·¥å…·è°ƒç”¨é—­ç¯ã€ä¸Šä¸‹æ–‡å‹ç¼©
- åœ¨ä¼šè¯ç»“ï¿½?è¾¾åˆ°è¿­ä»£ä¸Šé™æ—¶ï¼Œè§¦å‘ä¸€æ¬¡â€œç”¨æˆ·åå¥½â€æç‚¼å¹¶å†™å…¥ Markdownï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡å¼€å…³ï¼‰
"""
from __future__ import annotations

import json
from typing import Any, AsyncGenerator, Dict, List, Optional

from core.model_manager import model_manager
from core.memory import MemoryManager
from core.prompts import get_system_message
from core.ltm import LTMMarkdown, ltm_md_enabled
from services.file_store import (
    get_file_content_by_id,
    get_file_path_by_id,
    get_image_as_base64,
    is_image_file
)
from tools.manager import tool_manager


def _truncate_large_tool_result(tool_result: Dict[str, Any]) -> Dict[str, Any]:
    """æˆªæ–­å¤§å‹å·¥å…·ç»“æœï¼Œé¿å…ä¸Šä¸‹æ–‡çˆ†ç‚¸

    ç­–ç•¥ï¼š
    1. æ£€æµ‹ base64 ç¼–ç çš„æ•°æ®ï¼ˆæˆªå›¾ã€PDFç­‰ï¼‰
    2. ç¼“å­˜åˆ°file_storeï¼Œè·å–file_id
    3. è¿”å›file_id + å…ƒæ•°æ®ï¼ˆLLMå¯ä»¥åç»­ä½¿ç”¨ï¼‰
    4. ä¿ç•™æ‘˜è¦ä¿¡æ¯

    Args:
        tool_result: åŸå§‹å·¥å…·ç»“æœï¼Œæ ¼å¼ï¼š{"role": "tool", "content": "...", "name": "..."}

    Returns:
        æˆªæ–­åçš„å·¥å…·ç»“æœ
    """
    import os
    from services.file_store import cache_base64_data

    # è·å–æˆªæ–­é˜ˆå€¼ï¼ˆç¯å¢ƒå˜é‡é…ç½®ï¼Œé»˜è®¤10KBï¼‰
    try:
        max_size = int(os.getenv("TOOL_RESULT_MAX_SIZE", "10240"))  # 10KB
    except Exception:
        max_size = 10240

    content_str = tool_result.get("content", "")

    # å¦‚æœå†…å®¹ä¸å¤§ï¼Œç›´æ¥è¿”å›
    if len(content_str) <= max_size:
        return tool_result

    # å°è¯•è§£æJSON
    try:
        content_data = json.loads(content_str)
    except json.JSONDecodeError:
        # ä¸æ˜¯JSONï¼Œç›´æ¥æˆªæ–­æ–‡æœ¬
        truncated_content = content_str[:max_size] + f"\n\n[... å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­ {len(content_str)} å­—ç¬¦ä¸­çš„ {len(content_str) - max_size} å­—ç¬¦]"
        return {
            **tool_result,
            "content": truncated_content
        }

    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤§å‹ base64 æ•°æ®
    if isinstance(content_data, dict) and "data" in content_data:
        data = content_data["data"]
        truncated = False

        # å¤„ç† base64 ç¼–ç çš„å›¾ç‰‡
        if isinstance(data, dict) and "screenshot" in data and isinstance(data["screenshot"], str):
            original_size = len(data["screenshot"])
            if original_size > 1000:  # å¤§äº1000å­—ç¬¦
                # ã€å…³é”®ä¿®å¤ã€‘ç¼“å­˜base64æ•°æ®
                file_id = cache_base64_data(
                    data["screenshot"],
                    file_type="screenshot",
                    metadata={
                        "format": data.get("format", "png"),
                        "url": data.get("url"),
                        "original_size": original_size
                    }
                )

                # æ›¿æ¢base64ä¸ºfile_idå¼•ç”¨
                data["screenshot"] = data["screenshot"][:100] + "...[å·²ç¼“å­˜]"
                data["screenshot_size"] = f"{original_size} å­—ç¬¦ (~{original_size // 1024}KB)"
                data["screenshot_file_id"] = file_id  # âœ… LLMå¯ä»¥ä½¿ç”¨è¿™ä¸ªID
                data["screenshot_truncated"] = True
                data["_summary"] = f"âœ… æˆªå›¾å·²æˆåŠŸç”Ÿæˆå¹¶ç¼“å­˜ï¼ˆfile_id: {file_id}ï¼‰ã€‚ä½¿ç”¨ save_cached_file å·¥å…·å¯å°†å…¶ä¿å­˜åˆ°æœ¬åœ°ã€‚"
                truncated = True

        # å¤„ç† base64 ç¼–ç çš„ PDF
        if isinstance(data, dict) and "pdf" in data and isinstance(data["pdf"], str):
            original_size = len(data["pdf"])
            if original_size > 1000:
                # ã€å…³é”®ä¿®å¤ã€‘ç¼“å­˜base64æ•°æ®
                file_id = cache_base64_data(
                    data["pdf"],
                    file_type="pdf",
                    metadata={
                        "format": data.get("format", "A4"),
                        "url": data.get("url"),
                        "original_size": original_size
                    }
                )

                # æ›¿æ¢base64ä¸ºfile_idå¼•ç”¨
                data["pdf"] = data["pdf"][:100] + "...[å·²ç¼“å­˜]"
                data["pdf_size"] = f"{original_size} å­—ç¬¦ (~{original_size // 1024}KB)"
                data["pdf_file_id"] = file_id  # âœ… LLMå¯ä»¥ä½¿ç”¨è¿™ä¸ªID
                data["pdf_truncated"] = True
                data["_summary"] = f"âœ… PDFå·²æˆåŠŸç”Ÿæˆå¹¶ç¼“å­˜ï¼ˆfile_id: {file_id}ï¼‰ã€‚ä½¿ç”¨ save_cached_file å·¥å…·å¯å°†å…¶ä¿å­˜åˆ°æœ¬åœ°ã€‚"
                truncated = True

        # å¤„ç†é•¿æ–‡æœ¬å†…å®¹
        if isinstance(data, dict) and "text" in data and isinstance(data["text"], str):
            original_size = len(data["text"])
            if original_size > max_size:
                data["text"] = data["text"][:max_size] + f"\n\n...[æ–‡æœ¬è¿‡é•¿ï¼Œå·²æˆªæ–­ {original_size - max_size} å­—ç¬¦]"
                data["text_size"] = f"{original_size} å­—ç¬¦"
                data["text_truncated"] = True
                truncated = True

        if truncated:
            # é‡æ–°åºåˆ—åŒ–
            return {
                **tool_result,
                "content": json.dumps(content_data, ensure_ascii=False)
            }

    # å¦‚æœæ²¡æœ‰ç‰¹æ®Šå¤„ç†ï¼Œä½†å†…å®¹ä»ç„¶å¾ˆå¤§ï¼Œç›´æ¥æˆªæ–­JSON
    if len(content_str) > max_size:
        return {
            **tool_result,
            "content": content_str[:max_size] + f"\n\n[... JSONè¿‡å¤§ï¼Œå·²æˆªæ–­]"
        }

    return tool_result


async def _process_subagent_report(
    tool_result: Dict[str, Any],
    next_round_images: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """å¤„ç†SubAgentæŠ¥å‘Šï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼‰

    Args:
        tool_result: SubAgentå·¥å…·è¿”å›ç»“æœ
        next_round_images: å›¾ç‰‡åˆ—è¡¨ï¼ˆä¼šè¢«ä¿®æ”¹ï¼Œæ·»åŠ artifactsä¸­çš„å›¾ç‰‡ï¼‰

    Returns:
        {
            "memory_message": {...},  # æ³¨å…¥åˆ°ä¸»Agentè®°å¿†çš„ç´§å‡‘æ¶ˆæ¯
            "user_message": "..."      # å±•ç¤ºç»™ç”¨æˆ·çš„æ ¼å¼åŒ–æ¶ˆæ¯
        }
    """
    import logging
    logger = logging.getLogger(__name__)

    try:
        # è§£æSubAgentæŠ¥å‘Š
        content_str = tool_result.get("content", "{}")
        report = json.loads(content_str)

        # æå–æŠ¥å‘Šå­—æ®µ
        if isinstance(report, dict) and not report.get("error", False):
            summary = report.get("summary", "SubAgentæ‰§è¡Œå®Œæˆ")
            key_findings = report.get("key_findings", [])
            artifacts = report.get("artifacts", [])
            todos_completed = report.get("todos_completed", 0)
            todos_total = report.get("todos_total", 0)
            iterations = report.get("iterations", 0)
            subagent_name = report.get("subagent", "SubAgent")

            # å¤„ç†artifactsï¼šå¦‚æœæ˜¯å›¾ç‰‡ï¼Œæ³¨å…¥åˆ°next_round_images
            for artifact_id in artifacts:
                file_path = get_file_path_by_id(artifact_id)
                if file_path and is_image_file(file_path):
                    image_data = get_image_as_base64(artifact_id)
                    if image_data:
                        next_round_images.append({
                            "type": "image_url",
                            "image_url": {
                                "url": image_data["url"]
                            }
                        })
                        logger.info(f"ğŸ“¸ SubAgentè¿”å›æˆªå›¾ file_id: {artifact_id}ï¼Œå°†åœ¨ä¸‹ä¸€è½®æ³¨å…¥")

            # ç”Ÿæˆç”¨æˆ·å‹å¥½çš„æ ¼å¼åŒ–æ¶ˆæ¯
            user_message = f"""
âœ… **{subagent_name}æ‰§è¡ŒæŠ¥å‘Š**

**æ‘˜è¦**ï¼š{summary}

**å…³é”®å‘ç°**ï¼š
{chr(10).join(f"- {finding}" for finding in key_findings[:10]) if key_findings else "ï¼ˆæ— ï¼‰"}

**é™„ä»¶**ï¼š{len(artifacts)}ä¸ªæ–‡ä»¶ï¼ˆfile_id: {", ".join(artifacts[:5])}{"..." if len(artifacts) > 5 else ""}ï¼‰

**æ‰§è¡Œæƒ…å†µ**ï¼šå®Œæˆ {todos_completed}/{todos_total} ä¸ªä»»åŠ¡ï¼Œè¿­ä»£ {iterations} è½®
"""

            # ç”Ÿæˆæ³¨å…¥åˆ°memoryçš„ç´§å‡‘æ¶ˆæ¯
            memory_message = {
                "tool_call_id": tool_result.get("tool_call_id"),
                "role": "tool",
                "name": tool_result.get("name"),
                "content": json.dumps({
                    "error": False,
                    "data": {
                        "subagent": subagent_name,
                        "summary": summary,
                        "key_findings": key_findings[:5],  # åªä¿ç•™å‰5æ¡
                        "artifacts_count": len(artifacts),
                        "todos_status": f"{todos_completed}/{todos_total}",
                        "iterations": iterations
                    }
                }, ensure_ascii=False)
            }

            return {
                "memory_message": memory_message,
                "user_message": user_message
            }

        else:
            # SubAgentæ‰§è¡Œå¤±è´¥
            error_message = report.get("message", "SubAgentæ‰§è¡Œå¤±è´¥")
            user_message = f"âŒ SubAgentæ‰§è¡Œå¤±è´¥ï¼š{error_message}"

            memory_message = {
                "tool_call_id": tool_result.get("tool_call_id"),
                "role": "tool",
                "name": tool_result.get("name"),
                "content": json.dumps({
                    "error": True,
                    "message": error_message
                }, ensure_ascii=False)
            }

            return {
                "memory_message": memory_message,
                "user_message": user_message
            }

    except Exception as e:
        logger.error(f"å¤„ç†SubAgentæŠ¥å‘Šå¼‚å¸¸: {e}")
        # é™çº§å¤„ç†ï¼šè¿”å›åŸå§‹å†…å®¹
        return {
            "memory_message": tool_result,
            "user_message": tool_result.get("content", "SubAgentæŠ¥å‘Šè§£æå¤±è´¥")
        }


async def agent_main_loop(
    user_input: str,
    file_ids: Optional[List[str]] = None,
    max_iterations: int = 999,
    save_ltm: bool = False,
    history_messages: Optional[List[Dict[str, Any]]] = None,
    session_id: Optional[str] = None,  # ä¼šè¯IDï¼ˆå‰ç«¯å¯¹è¯çª—å£IDï¼‰
) -> AsyncGenerator[Dict[str, Any], None]:
    """Agent ä¸»å¾ªç¯ï¼šæ”¯æŒè®°å¿†ã€å‹ç¼©ã€å·¥å…·è°ƒç”¨ä¸é•¿æœŸè®°å¿†æç‚¼

    æ ¸å¿ƒä¿®æ”¹ï¼šæ¥æ”¶å‰ç«¯ä¼ é€’çš„ session_idï¼Œå®ç°å¯¹è¯çª—å£çº§åˆ«çš„ä¸Šä¸‹æ–‡æŒä¹…åŒ–

    Args:
        user_input: å½“å‰ç”¨æˆ·è¾“å…¥
        file_ids: é™„ä»¶IDåˆ—è¡¨
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        save_ltm: æ˜¯å¦ä¿å­˜é•¿æœŸè®°å¿†
        history_messages: å†å²æ¶ˆæ¯åˆ—è¡¨ï¼ˆå‰ç«¯ä¼ é€’ï¼‰ï¼Œæ ¼å¼ï¼š[{"role": "user|assistant", "content": "..."}]
        session_id: ä¼šè¯IDï¼ˆå‰ç«¯å¯¹è¯çª—å£IDï¼Œç”¨äºTODOå’Œå¯¹è¯æŒä¹…åŒ–éš”ç¦»ï¼‰

    Yields:
        äº‹ä»¶æµï¼š{"type": "meta|content|tool_call|tool_result|done", "data": ...}
    """
    # åˆå§‹åŒ–æ—¥å¿—
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    # æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨å‰ç«¯ä¼ é€’çš„ session_id åˆ›å»º MemoryManager
    # å¦‚æœå‰ç«¯æœªä¼ é€’ï¼Œåˆ™è‡ªåŠ¨ç”Ÿæˆæ–° UUIDï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    memory = MemoryManager(session_id=session_id)

    # æ—¥å¿—è®°å½•ä¼šè¯IDï¼Œä¾¿äºè°ƒè¯•å’Œè¿½è¸ª
    logger.info(f"ğŸ¯ Agentä¸»å¾ªç¯å¯åŠ¨: session_id={memory.session_id}")

    # 1) æ³¨å…¥ç³»ç»Ÿæç¤ºï¼ˆå«ä¸ƒæµ·äººæ ¼ + å·¥å…·è¯´æ˜ï¼‰
    tool_descriptions = tool_manager.get_tool_descriptions()
    system_msg = get_system_message(tool_descriptions)
    memory.add_message(system_msg)

    # 2) åŠ è½½é•¿æœŸè®°å¿†ï¼ˆLTMï¼‰åˆ°ä¸Šä¸‹æ–‡
    if ltm_md_enabled():
        try:
            ltm = LTMMarkdown()
            ltm_content = ltm.read_all()
            if ltm_content and ltm_content.strip():
                memory.add_message({
                    "role": "system",
                    "content": f"## å“¥å“¥çš„é•¿æœŸåå¥½ï¼ˆä»å†å²å¯¹è¯ä¸­æç‚¼ï¼‰\n\n{ltm_content}"
                })
                logger.info(f"âœ… å·²åŠ è½½å®Œæ•´é•¿æœŸè®°å¿†åˆ°ä¸Šä¸‹æ–‡")
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ è½½é•¿æœŸè®°å¿†å¤±è´¥: {e}")

    # 3) æ³¨å…¥å†å²æ¶ˆæ¯ï¼ˆå¦‚æœå‰ç«¯ä¼ é€’äº†å†å²ï¼‰
    if history_messages:
        # åªåŠ è½½ç”¨æˆ·å’ŒåŠ©æ‰‹çš„å†å²æ¶ˆæ¯ï¼Œè·³è¿‡ç³»ç»Ÿæ¶ˆæ¯ï¼ˆç³»ç»Ÿæ¶ˆæ¯å·²ç»åœ¨æ­¥éª¤1æ³¨å…¥ï¼‰
        for msg in history_messages:
            if msg.get("role") in ["user", "assistant"]:
                memory.add_message(msg)

    # 4) æ³¨å…¥é™„ä»¶å†…å®¹
    # - å›¾ç‰‡æ–‡ä»¶ï¼šè½¬æ¢ä¸ºbase64å¹¶ä½¿ç”¨visionæ ¼å¼
    # - æ–‡æœ¬æ–‡ä»¶ï¼šä½œä¸ºsystemæ¶ˆæ¯æ³¨å…¥
    image_contents = []  # å­˜å‚¨å›¾ç‰‡çš„base64æ•°æ®

    if file_ids:
        for fid in file_ids:
            file_path = get_file_path_by_id(fid)

            # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡æ–‡ä»¶
            if file_path and is_image_file(file_path):
                # è·å–å›¾ç‰‡çš„base64ç¼–ç 
                image_data = get_image_as_base64(fid)
                if image_data:
                    image_contents.append({
                        "type": "image_url",
                        "image_url": {
                            "url": image_data["url"]
                        }
                    })
                    logger.info(f"âœ… å·²åŠ è½½å›¾ç‰‡æ–‡ä»¶: {fid} ({image_data['mime_type']})")
            else:
                # æ–‡æœ¬æ–‡ä»¶ï¼Œç›´æ¥è¯»å–å†…å®¹
                content = get_file_content_by_id(fid)
                if content:
                    snippet = content[:20000]
                    memory.add_message({
                        "role": "system",
                        "content": f"[é™„ä»¶:{fid}]\n{snippet}",
                    })
                    logger.info(f"âœ… å·²åŠ è½½æ–‡æœ¬æ–‡ä»¶: {fid}")

    # 5) æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
    # å¦‚æœæœ‰å›¾ç‰‡ï¼Œä½¿ç”¨å¤šæ¨¡æ€æ¶ˆæ¯æ ¼å¼ï¼ˆOpenAI Visionæ ¼å¼ï¼‰
    if image_contents:
        # æ„é€ å¤šæ¨¡æ€æ¶ˆæ¯ï¼š[{"type": "text", "text": "..."}, {"type": "image_url", "image_url": {...}}]
        user_message_content = [
            {"type": "text", "text": user_input}
        ]
        user_message_content.extend(image_contents)

        memory.add_message({
            "role": "user",
            "content": user_message_content
        })
        logger.info(f"âœ… å·²æ·»åŠ å¤šæ¨¡æ€ç”¨æˆ·æ¶ˆæ¯ï¼ˆæ–‡æœ¬ + {len(image_contents)}å¼ å›¾ç‰‡ï¼‰")
    else:
        # çº¯æ–‡æœ¬æ¶ˆæ¯
        memory.add_message({"role": "user", "content": user_input})

    # 6) ä¸Šä¸‹æ–‡å‹ç¼©æ£€æŸ¥
    compact_state = await memory.check_and_compact()
    yield {"type": "meta", "data": {"compact": compact_state}}

    # 7) åŠ è½½å·²å­˜åœ¨çš„TODOï¼ˆè·¨ä¼šè¯æ¢å¤ï¼‰- åªåŠ è½½å½“å‰sessionçš„TODO
    from services.todo_store import list_todos
    existing_todos = list_todos(session_id=memory.session_id)  # ğŸ”‘ å…³é”®ï¼šä¼ å…¥session_idéš”ç¦»TODO

    if existing_todos:
        pending_todos = [t for t in existing_todos if t.status in ["pending", "in_progress"]]

        if pending_todos:
            logger.info(f"âœ… æ£€æµ‹åˆ° {len(pending_todos)} ä¸ªæœªå®Œæˆçš„TODOï¼Œå‡†å¤‡ç»§ç»­æ‰§è¡Œ")

            # æ³¨å…¥System Reminderï¼Œæç¤ºæ¨¡å‹ç»§ç»­æ‰§è¡Œ
            todo_summary = "\n".join([
                f"- [{t.status}] {t.title}: {t.description or 'æ— æè¿°'}"
                for t in pending_todos[:10]  # æœ€å¤šæ˜¾ç¤º10ä¸ª
            ])

            memory.add_message({
                "role": "system",
                "content": f"""<system-reminder>
ğŸ“‹ **æ£€æµ‹åˆ°æœªå®Œæˆçš„TODOä»»åŠ¡**

ä½ ä¹‹å‰åˆ›å»ºäº†ä»¥ä¸‹ä»»åŠ¡æ¸…å•ï¼Œç°åœ¨å¯ä»¥ç»§ç»­æ‰§è¡Œï¼š

{todo_summary}

è¯·ç»§ç»­å®Œæˆè¿™äº›æœªå®Œæˆçš„ä»»åŠ¡ã€‚ä½ å¯ä»¥ï¼š
1. ä½¿ç”¨ update_todo æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸º in_progress æˆ– completed
2. ç›´æ¥è°ƒç”¨ç›¸å…³å·¥å…·ç»§ç»­æ‰§è¡Œ
3. å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œæ ‡è®°ä¸º completed

ä¸éœ€è¦é‡æ–°åˆ›å»ºTODO LISTï¼Œç›´æ¥ç»§ç»­æ‰§è¡Œå³å¯ã€‚
</system-reminder>"""
            })

            yield {
                "type": "meta",
                "data": {
                    "todos_loaded": True,
                    "pending_count": len(pending_todos),
                    "total_count": len(existing_todos)
                }
            }

    # 8) ä¸»å¾ªç¯ï¼ˆæ€è€ƒâ†’å·¥å…·â†’å†æ€è€ƒï¼‰
    main_client = model_manager.get_model("main")
    openai_tools = tool_manager.get_openai_tools()

    iteration = 0
    while iteration < max_iterations:
        iteration += 1
        logger.info(f"ğŸ“ Iteration {iteration}/{max_iterations}")

        try:
            # è·å–ä¸Šä¸‹æ–‡å¹¶è°ƒç”¨æ¨¡å‹
            context = memory.get_context()
            try:
                resp = await main_client.chat(context, tools=openai_tools)
            except TypeError:
                resp = await main_client.chat(context)

            content = resp.get("content", "")
            raw_response = resp.get("raw")

            # è§£æ tool_callsï¼ˆOpenAI å…¼å®¹æ ¼å¼ï¼‰
            tool_calls = None
            if raw_response and hasattr(raw_response, "choices"):
                choice = raw_response.choices[0]
                if hasattr(choice.message, "tool_calls") and choice.message.tool_calls:
                    tool_calls = choice.message.tool_calls

            # è¾“å‡ºæ–‡æœ¬å†…å®¹ï¼ˆå¦‚æœ‰ï¼‰
            if content:
                logger.info(f"ğŸ“ æ¨¡å‹è¿”å›æ–‡æœ¬ï¼Œé•¿åº¦ {len(content)}")

                # é•¿å“åº”è‡ªåŠ¨ç¼“å­˜
                if len(content) > 5000:  # è¶…è¿‡5000å­—ç¬¦
                    from services.file_store import cache_base64_data
                    import base64

                    response_id = cache_base64_data(
                        base64.b64encode(content.encode()).decode(),
                        file_type="text",
                        metadata={"length": len(content)}
                    )

                    # æ·»åŠ ç¼“å­˜å¼•ç”¨çš„æ¶ˆæ¯
                    truncated_content = content[:500] + f"\n...[å®Œæ•´å†…å®¹å·²ç¼“å­˜: {response_id}ï¼Œä½¿ç”¨ save_cached_file å·¥å…·å¯ä¿å­˜åˆ°æœ¬åœ°]"
                    memory.add_message({"role": "assistant", "content": truncated_content})
                    logger.info(f"ğŸ’¾ é•¿å“åº”å·²ç¼“å­˜: {response_id}")
                else:
                    # çŸ­å“åº”ç›´æ¥ä¿å­˜
                    memory.add_message({"role": "assistant", "content": content})

                chunk_size = 1000
                for i in range(0, len(content), chunk_size):
                    yield {"type": "content", "data": content[i : i + chunk_size]}

            # åˆ¤æ–­æ˜¯å¦éœ€è¦ç»“æŸ
            if not tool_calls:
                logger.info(f"ğŸ æ— å·¥å…·è°ƒç”¨ï¼Œä»»åŠ¡ç»“æŸ (iteration={iteration})")
                if content:
                    # å¦‚æœè¿˜æ²¡æ·»åŠ æ¶ˆæ¯ï¼ˆé•¿å“åº”ç¼“å­˜æ—¶å·²æ·»åŠ ï¼‰ï¼Œåˆ™æ·»åŠ 
                    if len(content) <= 5000:
                        pass  # å·²åœ¨ä¸Šé¢æ·»åŠ è¿‡äº†

                # ä¿å­˜å¯¹è¯åˆ°ç£ç›˜
                memory.save_to_disk()
                logger.info(f"ğŸ’¾ å¯¹è¯å·²ä¿å­˜: session_id={memory.session_id}")

                # å°è¯•æç‚¼"ç”¨æˆ·åå¥½"å†™å…¥ Markdownï¼ˆä»…å½“å‰ç«¯æ˜ç¡®è¯·æ±‚æ—¶ï¼‰
                try:
                    if save_ltm:  # åªæœ‰å‰ç«¯æ˜ç¡®ä¼ é€’ save_ltm=True æ—¶æ‰è‡ªåŠ¨æç‚¼
                        ltm = LTMMarkdown()
                        pref = await ltm.summarize_preferences(memory.get_context())
                        if pref and pref.strip():
                            ltm.append_section("ç”¨æˆ·åå¥½æ€»ç»“", pref, tags=["preference"])
                            yield {"type": "meta", "data": {"ltm_saved": True, "path": ltm.path, "kind": "preferences"}}
                        else:
                            yield {"type": "meta", "data": {"ltm_saved": False, "reason": "empty_summary"}}
                except Exception as _e:
                    logger.warning(f"LTM å†™å…¥å¤±è´¥: {_e}")

                break

            # æœ‰å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œå·¥å…·
            yield {"type": "tool_call", "data": {"message": f"æ­£åœ¨è°ƒç”¨{len(tool_calls)}ä¸ªå·¥å…·.."}}

            assistant_msg = {
                "role": "assistant",
                "content": content or "",
                "tool_calls": [
                    {
                        "id": tc.id,
                        "type": "function",
                        "function": {
                            "name": tc.function.name,
                            "arguments": tc.function.arguments,
                        },
                    }
                    for tc in tool_calls
                ],
            }
            memory.add_message(assistant_msg)

            tool_call_dicts = [
                {
                    "id": tc.id,
                    "function": {
                        "name": tc.function.name,
                        "arguments": tc.function.arguments,
                    },
                }
                for tc in tool_calls
            ]

            tool_results = await tool_manager.execute_tool_calls(tool_call_dicts, session_id=memory.session_id)  # âœ… ä¼ é€’session_id

            # ã€å…³é”®ä¿®å¤ã€‘æ”¶é›†å·¥å…·è¿”å›çš„å›¾ç‰‡file_idï¼Œæ³¨å…¥åˆ°ä¸‹ä¸€è½®å¯¹è¯
            next_round_images = []

            for tool_result in tool_results:
                tool_name = tool_result.get("name", "unknown")

                # ğŸ”‘ æ ¸å¿ƒä¼˜åŒ–ï¼šæ£€æµ‹SubAgentæŠ¥å‘Šå¹¶ç‰¹æ®Šå¤„ç†
                is_subagent_report = tool_name.endswith("_subagent")

                if is_subagent_report:
                    # SubAgentæŠ¥å‘Šå¤„ç†é€»è¾‘
                    subagent_report = await _process_subagent_report(tool_result, next_round_images)

                    # æ³¨å…¥ç´§å‡‘æŠ¥å‘Šåˆ°è®°å¿†
                    memory.add_message(subagent_report["memory_message"])

                    # è¿”å›æ ¼å¼åŒ–æŠ¥å‘Šç»™å‰ç«¯
                    yield {
                        "type": "tool_result",
                        "data": {
                            "tool": tool_name,
                            "result": subagent_report["user_message"],
                        },
                    }
                else:
                    # æ™®é€šå·¥å…·å¤„ç†é€»è¾‘ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    truncated_result = _truncate_large_tool_result(tool_result)

                    # æ£€æŸ¥file_idï¼Œå¦‚æœæ˜¯å›¾ç‰‡åˆ™å‡†å¤‡æ³¨å…¥
                    try:
                        result_content = json.loads(tool_result.get("content", "{}"))
                        if isinstance(result_content, dict) and not result_content.get("error", False):
                            data = result_content.get("data", {})
                            if isinstance(data, dict) and "file_id" in data:
                                fid = data["file_id"]
                                file_path = get_file_path_by_id(fid)

                                if file_path and is_image_file(file_path):
                                    image_data = get_image_as_base64(fid)
                                    if image_data:
                                        next_round_images.append({
                                            "type": "image_url",
                                            "image_url": {
                                                "url": image_data["url"]
                                            }
                                        })
                                        logger.info(f"ğŸ“¸ æ£€æµ‹åˆ°æˆªå›¾ file_id: {fid}ï¼Œå°†åœ¨ä¸‹ä¸€è½®æ³¨å…¥åˆ°å¯¹è¯ä¸­")
                    except Exception as e:
                        logger.debug(f"è§£æå·¥å…·ç»“æœæ—¶å‡ºé”™ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")

                    # æ³¨å…¥åˆ°è®°å¿†
                    memory.add_message(truncated_result)

                    # è¿”å›ç»™å‰ç«¯
                    yield {
                        "type": "tool_result",
                        "data": {
                            "tool": tool_name,
                            "result": tool_result.get("content", ""),
                        },
                    }

            # ã€å…³é”®ä¿®å¤ã€‘å¦‚æœæœ‰æˆªå›¾ï¼Œå°†å…¶æ³¨å…¥åˆ°ä¸‹ä¸€è½®å¯¹è¯ä¸­ä¾›æ¨¡å‹åˆ†æ
            if next_round_images:
                screenshot_message = {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "ğŸ“¸ è¿™æ˜¯åˆšæ‰å·¥å…·æ‰§è¡Œåçš„æˆªå›¾ï¼Œè¯·åˆ†æé¡µé¢å†…å®¹ï¼š"
                        }
                    ] + next_round_images
                }
                memory.add_message(screenshot_message)
                logger.info(f"âœ… å·²æ³¨å…¥ {len(next_round_images)} å¼ æˆªå›¾åˆ°å¯¹è¯ä¸­ï¼Œæ¨¡å‹å¯ä»¥åœ¨ä¸‹ä¸€è½®åˆ†æ")

        except Exception as e:
            logger.error(f"âŒ Iteration {iteration} å¼‚å¸¸: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            yield {"type": "content", "data": f"\n\nâŒ æ‰§è¡Œå¼‚å¸¸ (Iteration {iteration}): {str(e)}\n"}
            break

    # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œä¹Ÿå°è¯•æç‚¼ä¸€æ¬¡ï¼ˆä»…å½“å‰ç«¯æ˜ç¡®è¯·æ±‚æ—¶ï¼‰
    if iteration >= max_iterations:
        import logging as _logging
        _logging.getLogger(__name__).warning(
            f"âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ä¸Šé™({max_iterations})ï¼Œå¾ªç¯æå‰é€€å‡º"
        )
        yield {
            "type": "content",
            "data": f"\n\nâš ï¸ ä»»åŠ¡æœªå®Œæˆï¼šè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°({max_iterations})ï¼Œå¯å°è¯•å¢åŠ  max_iterations å‚æ•°\n",
        }

        # ä¿å­˜å¯¹è¯åˆ°ç£ç›˜
        memory.save_to_disk()
        logger.info(f"ğŸ’¾ å¯¹è¯å·²ä¿å­˜: session_id={memory.session_id}")

        try:
            if save_ltm:  # åªæœ‰å‰ç«¯æ˜ç¡®ä¼ é€’ save_ltm=True æ—¶æ‰æç‚¼
                ltm = LTMMarkdown()
                pref = await ltm.summarize_preferences(memory.get_context())
                if pref and pref.strip():
                    ltm.append_section("ç”¨æˆ·åå¥½æ€»ç»“", pref, tags=["preference"])
                    yield {"type": "meta", "data": {"ltm_saved": True, "path": ltm.path, "kind": "preferences"}}
        except Exception:
            pass

    yield {"type": "done"}
