"""
æ·±åº¦æœç´¢SubAgent - ä¸“é—¨å¤„ç†ç½‘ç»œä¿¡æ¯æ·±åº¦æ”¶é›†ä»»åŠ¡

åŠŸèƒ½ï¼š
- é›†æˆTavilyå·¥å…·é›†ï¼ˆæœç´¢ã€æå–ã€æ˜ å°„ã€çˆ¬å–ï¼‰
- TODO LISTè§„åˆ’ï¼šåˆ†è§£å¤æ‚æœç´¢ä»»åŠ¡ä¸ºå¤šä¸ªå­æŸ¥è¯¢
- è‡ªä¸»ç­–ç•¥è°ƒæ•´ï¼šæ ¹æ®æœç´¢ç»“æœåŠ¨æ€ä¼˜åŒ–æŸ¥è¯¢
- ç»“æ„åŒ–æŠ¥å‘Šï¼šç”Ÿæˆç´§å‡‘çš„æœç´¢ç»“æœæ‘˜è¦

ä½¿ç”¨åœºæ™¯ï¼š
- å­¦æœ¯è®ºæ–‡æ·±åº¦æ£€ç´¢
- æŠ€æœ¯æ–‡æ¡£å…¨é¢æ”¶é›†
- å¤šæºä¿¡æ¯å¯¹æ¯”åˆ†æ
- æ·±åº¦ä¸»é¢˜ç ”ç©¶

ä¼˜åŒ–æ”¹è¿›ï¼š
- ç²¾ç®€ç³»ç»Ÿæç¤ºè¯ï¼Œæé«˜éµå¾ªç‡
- å¼ºåˆ¶ç½®ä¿¡åº¦æ ‡æ³¨å’ŒURLéªŒè¯
- è¦æ±‚äº¤å‰éªŒè¯å’Œæ¥æºå¯é æ€§æ£€æŸ¥
- åŒºåˆ†"éªŒè¯äº‹å®"vs"æ¨æµ‹å†…å®¹"
"""
from __future__ import annotations

from typing import Any, Dict

from core.subagent import SubAgent
from tools.tavily_wrapper import (
    TavilySearchTool,
    TavilyExtractTool,
    TavilyMapTool,
    TavilyCrawlTool
)
from tools.base import BaseTool


class SearchSubAgent(SubAgent):
    """æ·±åº¦æœç´¢SubAgent

    ä¸“é—¨å¤„ç†ç½‘ç»œä¿¡æ¯æ·±åº¦æ”¶é›†ï¼Œå…·å¤‡ï¼š
    - Tavilyå®Œæ•´å·¥å…·é›†
    - TODOè§„åˆ’èƒ½åŠ›
    - å¤šè½®æœç´¢ç­–ç•¥
    - åå¹»è§‰æœºåˆ¶
    """

    def _get_system_prompt(self) -> str:
        """ç²¾ç®€ç³»ç»Ÿæç¤ºè¯ï¼šå¼ºçº¦æŸåå¹»è§‰ + TODOå¤ç”¨æœºåˆ¶

        æ ¸å¿ƒæ”¹è¿›ï¼š
        - ç²¾ç®€æç¤ºè¯ï¼Œæé«˜éµå¾ªç‡
        - å¼ºåˆ¶ç½®ä¿¡åº¦æ ‡æ³¨
        - è¦æ±‚æ¥æºURLå’Œäº¤å‰éªŒè¯
        - æ˜ç¡®"æ¨æµ‹"vs"éªŒè¯äº‹å®"
        - æ™ºèƒ½å¤ç”¨ç°æœ‰TODOï¼Œé¿å…é‡å¤åˆ›å»º
        """
        tool_descriptions = self._get_tool_descriptions()
        return (
            "ä½ æ˜¯ã€æ·±åº¦æœç´¢é‡‡é›†ã€‘ä¸“å®¶SubAgentã€‚\n\n"
            "ğŸ“‹ æ‰§è¡Œæµç¨‹ï¼š\n"
            "1. ğŸ” **æ£€æŸ¥ç°æœ‰TODO**ï¼šå°è¯•è°ƒç”¨ create_subagent_todo\n"
            "   - å¦‚æœç³»ç»Ÿæç¤º'è·³è¿‡åˆ›å»ºæ–°TODO'ï¼Œè¯´æ˜å·²æœ‰æ´»è·ƒä»»åŠ¡ï¼Œç›´æ¥ç»§ç»­æ‰§è¡Œ\n"
            "   - å¦‚æœæ²¡æœ‰æ´»è·ƒTODOï¼Œç³»ç»Ÿä¼šåˆ›å»ºæ–°TODOåå†ç»§ç»­\n"
            "2. è°ƒç”¨ tavily_search/tavily_extract/tavily_map/tavily_crawl å®Œæˆæ£€ç´¢\n"
            "3. æ¯å®Œæˆä¸€ä¸ªä»»åŠ¡ç«‹å³ä½¿ç”¨ update_subagent_todo æ›´æ–°çŠ¶æ€\n\n"
            "ğŸ” æœç´¢å‚æ•°è¦æ±‚ï¼š\n"
            "- search_depth=advancedï¼ˆç¦æ­¢ä½¿ç”¨basicï¼‰\n"
            "- max_results=10-15\n"
            "- include_domains é”å®šæƒå¨æ¥æºï¼ˆarXivã€GitHubã€å®˜ç½‘ç­‰ï¼‰\n\n"
            "âš ï¸ åå¹»è§‰ç¡¬è§„åˆ™ï¼š\n"
            "- ä»»ä½•å…³é”®å£°æ˜å¿…é¡»é™„å¸¦URLæˆ–æ ‡æ³¨ã€æ¨æµ‹ã€‘\n"
            "- æ ¸å¿ƒå‘ç°éœ€è‡³å°‘2ä¸ªç‹¬ç«‹æ¥æºéªŒè¯\n"
            "- å¯¹æ¯æ¡å‘ç°æ ‡æ³¨ç½®ä¿¡åº¦ï¼š[é«˜/ä¸­/ä½]\n"
            "- æ— æ³•éªŒè¯çš„ä¿¡æ¯å¿…é¡»æ˜ç¡®æ ‡è®°ã€å¾…éªŒè¯ã€‘\n\n"
            "ğŸ“ è¾“å‡ºæ ¼å¼ï¼š\n"
            "```\n"
            "## æ‘˜è¦ï¼ˆâ‰¤200å­—ï¼‰\n"
            "## å…³é”®å‘ç°ï¼ˆ5-10æ¡ï¼‰\n"
            "- [é«˜ç½®ä¿¡åº¦] å‘ç°1 + URL + éªŒè¯æ¥æºæ•°\n"
            "- [ä¸­ç½®ä¿¡åº¦] å‘ç°2 + URL + éªŒè¯æ¥æºæ•°\n"
            "- [ä½ç½®ä¿¡åº¦] å‘ç°3 + URL + éªŒè¯æ¥æºæ•°\n"
            "- [æ¨æµ‹] å‘ç°4 + æ— URLæˆ–éœ€è¿›ä¸€æ­¥éªŒè¯\n"
            "## æ¥æºåˆ—è¡¨\n"
            "åŒ…å«URLã€æ ‡é¢˜ã€å‘å¸ƒæ—¶é—´/æ£€ç´¢æ—¶é—´\n"
            "```\n\n"
            "å¯ç”¨å·¥å…·ï¼š\n" + tool_descriptions + "\n\n"
            "âŒ ç¦æ­¢ï¼šé‡å¤åˆ›å»ºTODOã€ä»…è¾“å‡ºæ–‡å­—ä¸è°ƒç”¨å·¥å…·ã€ä½¿ç”¨basicæœç´¢ã€é—å¿˜URLæ ‡æ³¨"
        )

    def __init__(self, max_iterations: int = 999, model_pointer: str = "search_agent", session_id: str = "default"):
        self.model_pointer = model_pointer
        self.session_id = session_id  # ä¿å­˜session_idä¾›åç»­ä½¿ç”¨
        super().__init__(
            name="SearchSubAgent",
            description="æ·±åº¦æœç´¢ä¸“å®¶ï¼Œè´Ÿè´£å­¦æœ¯è®ºæ–‡ã€æŠ€æœ¯æ–‡æ¡£ã€æ–°é—»èµ„è®¯çš„å…¨é¢æ”¶é›†å’Œåˆ†æ",
            system_prompt=None,
            max_iterations=max_iterations,
            model_pointer=model_pointer,
            session_id=session_id
        )

    def _has_active_search_todos(self, task_description: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„searchç±»å‹TODO

        æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸å½“å‰ä»»åŠ¡ç›¸å…³çš„æœªå®ŒæˆTODOï¼Œé¿å…é‡å¤åˆ›å»º

        Args:
            task_description: å½“å‰ä»»åŠ¡æè¿°

        Returns:
            True ifå­˜åœ¨æœªå®Œæˆçš„search TODOï¼ŒFalse otherwise
        """
        try:
            from services.todo_store import list_todos

            todos = list_todos(session_id=self.session_id)

            # æ£€æŸ¥æ˜¯å¦æœ‰searchç±»å‹ä¸”æœªå®Œæˆçš„TODO
            active_todos = [
                t for t in todos
                if t.agent_type == "search"
                and t.status in ["pending", "in_progress"]
            ]

            # å¦‚æœæ²¡æœ‰æ´»è·ƒçš„search TODOï¼Œè¿”å›False
            if not active_todos:
                return False

            # ç®€å•å…³é”®è¯åŒ¹é…ï¼šå¦‚æœTODOæ ‡é¢˜åŒ…å«ä»»åŠ¡å…³é”®è¯ï¼Œè®¤ä¸ºæ˜¯ç›¸å…³ä»»åŠ¡
            task_keywords = set(task_description.lower().split()[:5])  # å–å‰5ä¸ªå…³é”®è¯

            for todo in active_todos:
                todo_keywords = set(todo.title.lower().split())
                # å¦‚æœå…³é”®è¯é‡å åº¦è¶…è¿‡50%ï¼Œè®¤ä¸ºæ˜¯åŒä¸€ä»»åŠ¡
                if len(task_keywords & todo_keywords) >= max(1, len(task_keywords) * 0.5):
                    return True

            return False
        except Exception:
            # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œå‡è®¾æ²¡æœ‰æ´»è·ƒTODOï¼Œç»§ç»­åˆ›å»ºæ–°çš„
            return False

    def _register_tools(self):
        """æ³¨å†ŒTavilyå·¥å…·é›†

        åŒ…æ‹¬ï¼š
        - tavily_search: æ·±åº¦æœç´¢
        - tavily_extract: URLå†…å®¹æå–
        - tavily_map: ç½‘ç«™ç»“æ„æ˜ å°„
        - tavily_crawl: æ·±åº¦çˆ¬å–
        """
        self.tools["tavily_search"] = TavilySearchTool()
        self.tools["tavily_extract"] = TavilyExtractTool()
        self.tools["tavily_map"] = TavilyMapTool()
        self.tools["tavily_crawl"] = TavilyCrawlTool()

    async def _generate_compact_report(self, final_content: str, iterations: int) -> Dict[str, Any]:
        """ç”Ÿæˆç´§å‡‘æŠ¥å‘Šå¹¶ä¿å­˜å®Œæ•´æŠ¥å‘Šåˆ°ç£ç›˜

        é‡å†™çˆ¶ç±»æ–¹æ³•ï¼Œæ·»åŠ æŠ¥å‘Šä¿å­˜åŠŸèƒ½

        Args:
            final_content: æœ€ç»ˆè¾“å‡ºå†…å®¹
            iterations: å½“å‰è¿­ä»£æ¬¡æ•°

        Returns:
            ç´§å‡‘ç‰ˆæŠ¥å‘Š + report_id
        """
        base_report = await super()._generate_compact_report(final_content, iterations)

        search_results = []
        for msg in self.memory.get_context():
            if msg.get("role") == "tool" and msg.get("name") in ["tavily_search", "tavily_extract", "tavily_map", "tavily_crawl"]:
                try:
                    import json
                    content = json.loads(msg.get("content", "{}"))
                    search_results.append({
                        "tool": msg.get("name"),
                        "data": content.get("data", {})
                    })
                except Exception:
                    pass

        from services.todo_store import list_todos
        all_todos = list_todos(session_id=self.session_id)
        subagent_todos = [
            {
                "title": t.title,
                "description": t.description,
                "status": t.status,
                "priority": t.priority
            }
            for t in all_todos
            if t.agent_type == "search"
        ]

        try:
            from services.report_store import save_report

            report_id = save_report(
                task_description="SearchSubAgent execution",
                summary=base_report.get("summary", ""),
                todos=subagent_todos,
                search_results=search_results,
                key_findings=base_report.get("key_findings", []),
                artifacts=base_report.get("artifacts", []),
                iterations=iterations,
                metadata={
                    "subagent": self.name,
                    "max_iterations": self.max_iterations,
                    "todos_completed": base_report.get("todos_completed", 0),
                    "todos_total": base_report.get("todos_total", 0)
                }
            )

            base_report["report_id"] = report_id
            base_report["message"] = f"âœ… æ·±åº¦æœç´¢å®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜: {report_id}"

        except Exception as e:
            import logging
            logging.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {str(e)}")
            base_report["report_save_error"] = str(e)

        return base_report


class SearchSubAgentTool(BaseTool):
    """SearchSubAgentè°ƒç”¨å·¥å…· - ä¸»Agentä½¿ç”¨æ­¤å·¥å…·è°ƒç”¨SearchSubAgent

    è¿™æ˜¯ä¸»Agentå’ŒSearchSubAgentä¹‹é—´çš„æ¡¥æ¢
    """

    name = "search_subagent"
    description = """ã€å¿…é¡»ä½¿ç”¨ã€‘å­¦æœ¯è®ºæ–‡/æŠ€æœ¯æ–‡æ¡£å…¨é¢æ”¶é›†ã€‚

âœ… å¿…é¡»ä½¿ç”¨åœºæ™¯ï¼š
- å­¦æœ¯è®ºæ–‡æ£€ç´¢ï¼ˆarXiv/Scholarï¼‰
- æŠ€æœ¯æ–‡æ¡£å…¨é¢æ”¶é›†ï¼ˆâ‰¥5 ä¸ªæƒå¨æ¥æºï¼‰
- å¤šæºä¿¡æ¯å¯¹æ¯”ä¸å¯ä¿¡åº¦è¯„ä¼°
- éœ€è¦é”å®šå®˜ç½‘ã€å®˜æ–¹åšå®¢ã€GitHub å®˜æ–¹ä»“åº“ç­‰æƒå¨æ¸ é“

âŒ ç¦æ­¢ä½¿ç”¨åœºæ™¯ï¼š
- å¿«é€ŸæŸ¥è¯¢åŸºç¡€æ¦‚å¿µï¼ˆè¯·ç›´æ¥ç”¨ tavily_searchï¼‰
- ä»…éœ€ 1-3 æ¡ç»“æœæˆ–ä¸éœ€è¦æ·±åº¦åˆ†æ

SubAgent ä¼šè‡ªåŠ¨ï¼š
1. è§„åˆ’å¹¶æŒç»­æ›´æ–° TODO
2. ä½¿ç”¨ tavily_search / tavily_map / tavily_crawl / tavily_extract çš„ advanced æ¨¡å¼é‡‡é›†æƒå¨ä¿¡æ¯
3. ç»“åˆ include_domains é”å®šå®˜æ–¹ä¸çŸ¥åç«™ç‚¹å¹¶è¿›è¡Œäº¤å‰éªŒè¯
4. ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Šï¼ˆå«æ¥æºã€æ—¶é—´ã€å¯ä¿¡åº¦ä¸åç»­å»ºè®®ï¼‰
"""

    async def execute(self, task_description: str, context: Dict[str, Any] = None, session_id: str = "default", **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œæ·±åº¦æœç´¢

        Args:
            task_description: è¯¦ç»†çš„æœç´¢ä»»åŠ¡æè¿°
                åº”åŒ…æ‹¬ï¼šæœç´¢ä¸»é¢˜ã€å…³é”®è¯ã€æœŸæœ›æ·±åº¦ã€æƒå¨æ¥æºè¦æ±‚
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            session_id: ä¼šè¯IDï¼Œç”¨äºTODOéš”ç¦»
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            ç´§å‡‘çš„ç»“æ„åŒ–æœç´¢æŠ¥å‘Š
        """
        subagent = SearchSubAgent(session_id=session_id)
        result = await subagent.execute(task_description, context)
        return result

    def get_openai_definition(self) -> dict:
        """OpenAIå·¥å…·å®šä¹‰"""
        return {
            "type": "function",
            "function": {
                "name": "search_subagent",
                "description": self.description,
                "parameters": {
                    "type": "object",
                    "properties": {
                        "task_description": {
                            "type": "string",
                            "description": """è¯¦ç»†çš„æœç´¢ä»»åŠ¡æè¿°ã€‚

å»ºè®®åŒ…æ‹¬ä»¥ä¸‹ä¿¡æ¯ï¼š
1. **æœç´¢ä¸»é¢˜**ï¼šæ˜ç¡®çš„ç ”ç©¶ä¸»é¢˜æˆ–é—®é¢˜
2. **å…³é”®è¯**ï¼šæ ¸å¿ƒå…³é”®è¯å’Œç›¸å…³æœ¯è¯­
3. **æƒå¨æ¥æº**ï¼šæœŸæœ›çš„æƒå¨ç½‘ç«™ï¼ˆå¦‚arXivã€GitHubã€å®˜æ–¹æ–‡æ¡£ï¼‰
4. **ä¿¡æ¯æ·±åº¦**ï¼šéœ€è¦æ‘˜è¦è¿˜æ˜¯è¯¦ç»†å†…å®¹
5. **æ—¶æ•ˆæ€§**ï¼šæ˜¯å¦éœ€è¦æœ€æ–°ä¿¡æ¯ï¼ˆå¦‚ï¼šè¿‡å»7å¤©ï¼‰

ç¤ºä¾‹ï¼š
"åœ¨arXiv.orgä¸Šæœç´¢DeepSeek R1ç›¸å…³è®ºæ–‡ï¼Œé‡ç‚¹å…³æ³¨æ¨¡å‹æ¶æ„å’Œè®­ç»ƒæ–¹æ³•ï¼Œéœ€è¦è¯¦ç»†çš„æŠ€æœ¯å†…å®¹"

"æ”¶é›†Python FastAPIçš„å®˜æ–¹æ–‡æ¡£ã€GitHubç¤ºä¾‹å’ŒStack Overflowå¸¸è§é—®é¢˜ï¼Œéœ€è¦å…¨é¢è¦†ç›–"
"""
                        },
                        "context": {
                            "type": "object",
                            "description": "ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰ã€‚å¯ä»¥åŒ…å«ä¹‹å‰çš„æœç´¢ç»“æœã€ç”¨æˆ·åå¥½ç­‰"
                        },
                        "session_id": {
                            "type": "string",
                            "description": "ä¼šè¯IDï¼Œç”¨äºTODOéš”ç¦»ï¼ˆç”±ä¸»Agentä¼ é€’ï¼‰"
                        }
                    },
                    "required": ["task_description"]
                }
            }
        }
